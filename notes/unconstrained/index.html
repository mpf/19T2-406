



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Home page for CPSC406 Term 2 2019">
      
      
        <link rel="canonical" href="https://friedlander.io/19T2-406/notes/unconstrained/">
      
      
        <meta name="author" content="Michael P. Friedlander and Babhru Joshi">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.6.0">
    
    
      
        <title>Unconstrained optimization - CPSC406 &mdash; Computational Optimization</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.1b62728e.css">
      
      
    
    
      <script src="../../assets/javascripts/modernizr.268332fc.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../assets/fonts/material-icons.css">
    
    
    
      
    
    
  </head>
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#unconstrained-optimization" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://friedlander.io/19T2-406" title="CPSC406 &mdash; Computational Optimization" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              CPSC406 &mdash; Computational Optimization
            </span>
            <span class="md-header-nav__topic">
              
                Unconstrained optimization
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href="../.." class="md-tabs__link">
        Home Page
      </a>
    
  </li>

      
        
      
        
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../background/" class="md-tabs__link md-tabs__link--active">
          Lecture notes
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../homework/" class="md-tabs__link">
          Homework
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../InclassActivity/mlactivity/mlactivity/" class="md-tabs__link">
          In-class Activity
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://friedlander.io/19T2-406" title="CPSC406 &mdash; Computational Optimization" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    CPSC406 &mdash; Computational Optimization
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Home Page" class="md-nav__link">
      Home Page
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../grades/" title="Grades" class="md-nav__link">
      Grades
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../schedule/" title="Schedule" class="md-nav__link">
      Schedule
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked>
    
    <label class="md-nav__link" for="nav-4">
      Lecture notes
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        Lecture notes
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../background/" title="Mathematical background" class="md-nav__link">
      Mathematical background
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Least_squares/" title="Least squares" class="md-nav__link">
      Least squares
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../QR_factorization/" title="QR factorization" class="md-nav__link">
      QR factorization
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Regularized_LS/" title="Regularized least squares" class="md-nav__link">
      Regularized least squares
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Non-linear_LS/" title="Non-linear least squares" class="md-nav__link">
      Non-linear least squares
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Unconstrained optimization
      </label>
    
    <a href="./" title="Unconstrained optimization" class="md-nav__link md-nav__link--active">
      Unconstrained optimization
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#optimality" class="md-nav__link">
    Optimality
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sufficient-conditions-in-1-d" class="md-nav__link">
    Sufficient conditions in 1-d
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-hessian-and-directional-derivatives" class="md-nav__link">
    Gradient, Hessian and directional derivatives
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sufficient-conditions-of-optimality" class="md-nav__link">
    Sufficient conditions of optimality
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Gradient_Descent/" title="Gradient descent" class="md-nav__link">
      Gradient descent
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Newtons_method/" title="Newton's method" class="md-nav__link">
      Newton's method
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Homework
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Homework
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../homework/" title="Submissions" class="md-nav__link">
      Submissions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../homework/hw1/hw1/" title="Homework 1" class="md-nav__link">
      Homework 1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../homework/hw2/hw2/" title="Homework 2" class="md-nav__link">
      Homework 2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../homework/hw3/hw3/" title="Homework 3" class="md-nav__link">
      Homework 3
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      In-class Activity
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        In-class Activity
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../InclassActivity/mlactivity/mlactivity/" title="Digit classification" class="md-nav__link">
      Digit classification
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#optimality" class="md-nav__link">
    Optimality
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sufficient-conditions-in-1-d" class="md-nav__link">
    Sufficient conditions in 1-d
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-hessian-and-directional-derivatives" class="md-nav__link">
    Gradient, Hessian and directional derivatives
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sufficient-conditions-of-optimality" class="md-nav__link">
    Sufficient conditions of optimality
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="unconstrained-optimization"><strong>Unconstrained Optimization</strong><a class="headerlink" href="#unconstrained-optimization" title="Permanent link">&para;</a></h1>
<p>In this lecture we consider unconstrained optimization given by</p>
<div>
<div class="MathJax_Preview">\begin{equation}\label{unconstrained_prob} \mathop{\text{minimize}}_{\vx \in \set{S}} f(\vx),\end{equation}</div>
<script type="math/tex; mode=display">\begin{equation}\label{unconstrained_prob} \mathop{\text{minimize}}_{\vx \in \set{S}} f(\vx),\end{equation}</script>
</div>
<p>where <span><span class="MathJax_Preview">f:\R^n \rightarrow \R</span><script type="math/tex">f:\R^n \rightarrow \R</script></span> and <span><span class="MathJax_Preview">\set{S}\subset \R^n</span><script type="math/tex">\set{S}\subset \R^n</script></span>. In the course, we will primarily consider minimization problems. This is because a 
maximizer of <span><span class="MathJax_Preview">f(\vx)</span><script type="math/tex">f(\vx)</script></span> is the minimzer of <span><span class="MathJax_Preview">-f(\vx)</span><script type="math/tex">-f(\vx)</script></span>. </p>
<h2 id="optimality"><strong>Optimality</strong><a class="headerlink" href="#optimality" title="Permanent link">&para;</a></h2>
<p>A point <span><span class="MathJax_Preview">\vx^*\in \set{S}</span><script type="math/tex">\vx^*\in \set{S}</script></span> is a </p>
<ol>
<li><strong>global minimizer</strong> of <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> if <span><span class="MathJax_Preview">f(\vx^*) \leq f(\vx)</span><script type="math/tex">f(\vx^*) \leq f(\vx)</script></span> for all <span><span class="MathJax_Preview">\vx\in \mS</span><script type="math/tex">\vx\in \mS</script></span></li>
<li><strong>global maximizer</strong> of <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> if <span><span class="MathJax_Preview">f(\vx^*) \geq f(\vx)</span><script type="math/tex">f(\vx^*) \geq f(\vx)</script></span> for all <span><span class="MathJax_Preview">\vx\in \mS</span><script type="math/tex">\vx\in \mS</script></span></li>
<li><strong>local minimizer</strong> of <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> if <span><span class="MathJax_Preview">f(\vx^*) \leq f(\vx)</span><script type="math/tex">f(\vx^*) \leq f(\vx)</script></span> for all <span><span class="MathJax_Preview">\vx\in \mS</span><script type="math/tex">\vx\in \mS</script></span> where <span><span class="MathJax_Preview">\|\vx-\vx^*\|_2 \leq\epsilon</span><script type="math/tex">\|\vx-\vx^*\|_2 \leq\epsilon</script></span> </li>
<li><strong>local maximizer</strong> of <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> if <span><span class="MathJax_Preview">f(\vx^*) \geq f(\vx)</span><script type="math/tex">f(\vx^*) \geq f(\vx)</script></span> for all <span><span class="MathJax_Preview">\vx\in \mS</span><script type="math/tex">\vx\in \mS</script></span> where <span><span class="MathJax_Preview">\|\vx-\vx^*\|_2 \leq\epsilon</span><script type="math/tex">\|\vx-\vx^*\|_2 \leq\epsilon</script></span> </li>
</ol>
<p>for some <span><span class="MathJax_Preview">\epsilon &gt; 0</span><script type="math/tex">\epsilon > 0</script></span>.  A maximizer (or minimizer) <span><span class="MathJax_Preview">\vx^*</span><script type="math/tex">\vx^*</script></span> of \eqref{unconstrained_prob} is a strict maximizer (or minimizer) if for all points 
in a neighborhood of <span><span class="MathJax_Preview">\vx^*</span><script type="math/tex">\vx^*</script></span>, the objective <span><span class="MathJax_Preview">f(x)</span><script type="math/tex">f(x)</script></span> does not attain the value of <span><span class="MathJax_Preview">f(\vx^{*})</span><script type="math/tex">f(\vx^{*})</script></span>. Equivalently, this definition of strict maximizer/minimizer 
in the global case can be stated as: <span><span class="MathJax_Preview">\vx^*</span><script type="math/tex">\vx^*</script></span> is a strict global  min or max if for all <span><span class="MathJax_Preview">\vx\in \set{S}</span><script type="math/tex">\vx\in \set{S}</script></span>, we have  <span><span class="MathJax_Preview">f(\vx^*) = f(\vx)</span><script type="math/tex">f(\vx^*) = f(\vx)</script></span> if and only if <span><span class="MathJax_Preview">\vx = \vx^*</span><script type="math/tex">\vx = \vx^*</script></span>.</p>
<p><center>
<img src="../img/lec6/unconstrained_opto.png" width = "400">
</center></p>
<p>The above figure shows that even if the optimality is attained, the optimal point may not be unique. There are cases when the optimal point is not attained or
even exist. An example of these cases are shown below</p>
<p><center>
    <img src="../img/lec6/oneoverx.png" width = "300">     <img src="../img/lec6/logfunction.png" width = "300">
</center></p>
<hr />
<p><span><span class="MathJax_Preview">\exa{1}</span><script type="math/tex">\exa{1}</script></span> Consider the minimization program</p>
<div>
<div class="MathJax_Preview">\mathop{\text{minimize}}_{x,y} \{f(x,y) = x + y: x^2 + y^2 \leq 2\}.</div>
<script type="math/tex; mode=display">\mathop{\text{minimize}}_{x,y} \{f(x,y) = x + y: x^2 + y^2 \leq 2\}.</script>
</div>
<p>The figure below shows the interaction bewtween the objective fuction and set <span><span class="MathJax_Preview">\{(x,y):x^2 + y^2 \leq 2\}</span><script type="math/tex">\{(x,y):x^2 + y^2 \leq 2\}</script></span>. The pink lines are the "level sets" and the arrows
are directions of descent. The optimal point is <span><span class="MathJax_Preview">\bmat -1\\ -1 \emat</span><script type="math/tex">\bmat -1\\ -1 \emat</script></span>.</p>
<p><center>
    <img src="../img/lec6/linear-2d-circleconstrained.png" width = "300"> <br />
</center></p>
<hr />
<p><span><span class="MathJax_Preview">\exa{2}</span><script type="math/tex">\exa{2}</script></span> Consider the minimization program</p>
<div>
<div class="MathJax_Preview"> \mathop{\text{minimize}}_{x,y} \{f(x,y) = \frac{x+y}{x^2+y^2+1}:x,y\in\R\}.</div>
<script type="math/tex; mode=display"> \mathop{\text{minimize}}_{x,y} \{f(x,y) = \frac{x+y}{x^2+y^2+1}:x,y\in\R\}.</script>
</div>
<p>The surface and contour plots of <span><span class="MathJax_Preview">f(x,y)</span><script type="math/tex">f(x,y)</script></span> are</p>
<div class="codehilite"><pre><span></span><span class="k">using</span> <span class="n">Plots</span><span class="p">;</span> <span class="n">pyplot</span><span class="p">()</span>
<span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">y</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">x</span><span class="o">^</span><span class="mi">2</span><span class="o">+</span><span class="n">y</span><span class="o">^</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="n">stop</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">length</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="n">stop</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">length</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">pyplot</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">700</span><span class="p">,</span><span class="mi">200</span><span class="p">))</span>
<span class="n">plot</span><span class="p">(</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="n">st</span><span class="o">=:</span><span class="n">surface</span><span class="p">,</span><span class="n">camera</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">30</span><span class="p">)),</span>
    <span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="n">st</span><span class="o">=:</span><span class="n">contour</span><span class="p">,</span><span class="n">camera</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">30</span><span class="p">)))</span>
</pre></div>

<p><img alt="" src="../figures/unconstrained_1_1.png" /></p>
<p>The global minimizer is <span><span class="MathJax_Preview">\begin{pmatrix} \frac{1}{\sqrt{2}},&amp; \frac{1}{\sqrt{2}} \end{pmatrix}</span><script type="math/tex">\begin{pmatrix} \frac{1}{\sqrt{2}},& \frac{1}{\sqrt{2}} \end{pmatrix}</script></span> and the 
global maximizer is <span><span class="MathJax_Preview">\bmatp -\frac{1}{\sqrt{2}}, &amp; -\frac{1}{\sqrt{2}} \ematp</span><script type="math/tex">\bmatp -\frac{1}{\sqrt{2}}, & -\frac{1}{\sqrt{2}} \ematp</script></span>. </p>
<hr />
<h2 id="sufficient-conditions-in-1-d"><strong>Sufficient conditions in 1-d</strong><a class="headerlink" href="#sufficient-conditions-in-1-d" title="Permanent link">&para;</a></h2>
<p>We will first look at 1-d function <span><span class="MathJax_Preview">f:\R→\R</span><script type="math/tex">f:\R→\R</script></span> and state sufficent conditions for optimality of a point <span><span class="MathJax_Preview">\vx</span><script type="math/tex">\vx</script></span> in the 
interrior of the set <span><span class="MathJax_Preview">\set{S}</span><script type="math/tex">\set{S}</script></span>.  Consider the following 1-d function</p>
<p><center>
    <img src="../img/lec6/stationary-points.png" width = "300"><br />
</center></p>
<p>The critial points of <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> in the above figure are <span><span class="MathJax_Preview">x \in \{ b ,\ c,\ d,\ e\}</span><script type="math/tex">x \in \{ b ,\ c,\ d,\ e\}</script></span> and these points satisfy <span><span class="MathJax_Preview">f'(x) =0</span><script type="math/tex">f'(x) =0</script></span>. We may be able
to use second derivative information to determine if these critial points are minimizer or maximizer. Precisely, for any function 
<span><span class="MathJax_Preview">f:\R\rightarrow\R</span><script type="math/tex">f:\R\rightarrow\R</script></span>, a point <span><span class="MathJax_Preview">x = x^*</span><script type="math/tex">x = x^*</script></span> is</p>
<ol>
<li>
<p>a local minimizer if <span><span class="MathJax_Preview">f'(x) = 0</span><script type="math/tex">f'(x) = 0</script></span> and <span><span class="MathJax_Preview">f''(x)&gt;0</span><script type="math/tex">f''(x)>0</script></span>, and</p>
</li>
<li>
<p>a local maximizer if <span><span class="MathJax_Preview">f'(x) = 0</span><script type="math/tex">f'(x) = 0</script></span> and <span><span class="MathJax_Preview">f''(x)&lt;0</span><script type="math/tex">f''(x)<0</script></span>.</p>
</li>
</ol>
<p>However, if both <span><span class="MathJax_Preview">f'(x) = 0</span><script type="math/tex">f'(x) = 0</script></span> and <span><span class="MathJax_Preview">f''(x)=0</span><script type="math/tex">f''(x)=0</script></span>, there is not enough information to draw any conclusion. As an example, consider <span><span class="MathJax_Preview">f(x) = x^3</span><script type="math/tex">f(x) = x^3</script></span> and
<span><span class="MathJax_Preview">f(x) = x^4</span><script type="math/tex">f(x) = x^4</script></span>. For both function, <span><span class="MathJax_Preview">f'(x) = 0</span><script type="math/tex">f'(x) = 0</script></span> and <span><span class="MathJax_Preview">f''(x) = 0</span><script type="math/tex">f''(x) = 0</script></span>, however <span><span class="MathJax_Preview">x = 0</span><script type="math/tex">x = 0</script></span> is saddle point of <span><span class="MathJax_Preview">x^3</span><script type="math/tex">x^3</script></span> and <span><span class="MathJax_Preview">x = 0</span><script type="math/tex">x = 0</script></span> is a  minimizer of <span><span class="MathJax_Preview">x^4</span><script type="math/tex">x^4</script></span>.</p>
<p>A proof of the sufficient condition of optimality follows directly from Taylor approximation of the function <span><span class="MathJax_Preview">f(x)</span><script type="math/tex">f(x)</script></span>. Consider the case where 
<span><span class="MathJax_Preview">f'(x^*) = 0</span><script type="math/tex">f'(x^*) = 0</script></span> and <span><span class="MathJax_Preview">f''(x^*)&gt;0</span><script type="math/tex">f''(x^*)>0</script></span> for some <span><span class="MathJax_Preview">x^*\in\set{S}</span><script type="math/tex">x^*\in\set{S}</script></span>. Then by Taylor's theorem of <span><span class="MathJax_Preview">f(x)</span><script type="math/tex">f(x)</script></span> at <span><span class="MathJax_Preview">x = x^*</span><script type="math/tex">x = x^*</script></span>, we get</p>
<div>
<div class="MathJax_Preview">f(x) = f(x^*) + \underbrace{f'(x^*)(x-x^*)}_{ =\ 0} + \underbrace{\frac{1}{2}f''(x^*)(x-x^*)^2}_{\text{strictly positive}} + 
\underbrace{O((x-x^*)^3)}_{\text{small}}</div>
<script type="math/tex; mode=display">f(x) = f(x^*) + \underbrace{f'(x^*)(x-x^*)}_{ =\ 0} + \underbrace{\frac{1}{2}f''(x^*)(x-x^*)^2}_{\text{strictly positive}} + 
\underbrace{O((x-x^*)^3)}_{\text{small}}</script>
</div>
<p>for <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span> close to <span><span class="MathJax_Preview">x^*</span><script type="math/tex">x^*</script></span>. So <span><span class="MathJax_Preview">f(x) &gt; f(x^*)</span><script type="math/tex">f(x) > f(x^*)</script></span> for all <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span> near <span><span class="MathJax_Preview">x^*</span><script type="math/tex">x^*</script></span>, which imples <span><span class="MathJax_Preview">x^*</span><script type="math/tex">x^*</script></span> is local minimizer. Similarly, we can prove <span><span class="MathJax_Preview">f(x^*)=0</span><script type="math/tex">f(x^*)=0</script></span> and
<span><span class="MathJax_Preview">f''(x^*)&lt;0</span><script type="math/tex">f''(x^*)<0</script></span> implies <span><span class="MathJax_Preview">x^*</span><script type="math/tex">x^*</script></span> is a local maximizer. In the next section we will generalize these sufficient condition for any real valued function 
<span><span class="MathJax_Preview">f:\R^n \rightarrow \R</span><script type="math/tex">f:\R^n \rightarrow \R</script></span>.</p>
<h2 id="gradient-hessian-and-directional-derivatives"><strong>Gradient, Hessian and directional derivatives</strong><a class="headerlink" href="#gradient-hessian-and-directional-derivatives" title="Permanent link">&para;</a></h2>
<p>For a differentiable function <span><span class="MathJax_Preview">f:\R^n\to\R</span><script type="math/tex">f:\R^n\to\R</script></span>, the gradient of <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> at <span><span class="MathJax_Preview">\vx</span><script type="math/tex">\vx</script></span> is a vector in <span><span class="MathJax_Preview">\R^n</span><script type="math/tex">\R^n</script></span>. The gradient of <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> at <span><span class="MathJax_Preview">\vx</span><script type="math/tex">\vx</script></span> contain the partial 
derivative of <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> at <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span> and is given by</p>
<div>
<div class="MathJax_Preview">\nabla f(x) = \bmat\frac{\partial f(x)}{\partial x_1}\\\frac{\partial f(x)}{\partial x_2}\\\vdots\\
\frac{\partial f(x)}{\partial x_n}\\\emat.
</div>
<script type="math/tex; mode=display">\nabla f(x) = \bmat\frac{\partial f(x)}{\partial x_1}\\\frac{\partial f(x)}{\partial x_2}\\\vdots\\
\frac{\partial f(x)}{\partial x_n}\\\emat.
</script>
</div>
<p>Similarly, the Hessian of <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> at <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span> is a symmetric matrix in <span><span class="MathJax_Preview">\R^{n\times n}</span><script type="math/tex">\R^{n\times n}</script></span> that contain second partial derivative information and is given by</p>
<div>
<div class="MathJax_Preview">
\nabla^2 f(x) = 
\bmat
\frac{\partial f^2(x)}{\partial x_1\partial x_1} &amp; \frac{\partial f^2(x)}{\partial x_1\partial x_2} &amp; \cdots &amp; 
\frac{\partial f^2(x)}{\partial x_1\partial x_n}\\
 \frac{\partial f^2(x)}{\partial x_2\partial x_1} &amp; 
  \frac{\partial f^2(x)}{\partial x_2\partial x_2}&amp; \cdots &amp;
   \frac{\partial f^2(x)}{\partial x_2\partial x_n}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
 \frac{\partial f^2(x)}{\partial x_n\partial x_1} &amp;  
 \frac{\partial f^2(x)}{\partial x_n\partial x_2} &amp; \cdots &amp;  \frac{\partial f^2(x)}{\partial x_n\partial x_n}\\
\emat
</div>
<script type="math/tex; mode=display">
\nabla^2 f(x) = 
\bmat
\frac{\partial f^2(x)}{\partial x_1\partial x_1} & \frac{\partial f^2(x)}{\partial x_1\partial x_2} & \cdots & 
\frac{\partial f^2(x)}{\partial x_1\partial x_n}\\
 \frac{\partial f^2(x)}{\partial x_2\partial x_1} & 
  \frac{\partial f^2(x)}{\partial x_2\partial x_2}& \cdots &
   \frac{\partial f^2(x)}{\partial x_2\partial x_n}\\
\vdots & \vdots & \ddots & \vdots \\
 \frac{\partial f^2(x)}{\partial x_n\partial x_1} &  
 \frac{\partial f^2(x)}{\partial x_n\partial x_2} & \cdots &  \frac{\partial f^2(x)}{\partial x_n\partial x_n}\\
\emat
</script>
</div>
<p>For example, for a function <span><span class="MathJax_Preview">f(x) = x_1^2 + 8x_1x_2  - 2x_3^3</span><script type="math/tex">f(x) = x_1^2 + 8x_1x_2  - 2x_3^3</script></span>, its gradiet is <span><span class="MathJax_Preview">\nabla f(x) = \bmat 2x_1 + 8x_2\\8x_1\\-6x_3^2\emat</span><script type="math/tex">\nabla f(x) = \bmat 2x_1 + 8x_2\\8x_1\\-6x_3^2\emat</script></span>,
and its Hessian is <span><span class="MathJax_Preview">\nabla^2 f(x) = \bmat 2 &amp; 8 &amp; 0 \\ 8 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; -12x_3\emat.</span><script type="math/tex">\nabla^2 f(x) = \bmat 2 & 8 & 0 \\ 8 & 0 & 0 \\ 0 & 0 & -12x_3\emat.</script></span></p>
<p>Next, we look at directional derivatives. For a differentiable function <span><span class="MathJax_Preview">f:\R^n\to \R</span><script type="math/tex">f:\R^n\to \R</script></span>, the directional derivative in the direction of <span><span class="MathJax_Preview">\vd \in \R^n</span><script type="math/tex">\vd \in \R^n</script></span> is </p>
<div>
<div class="MathJax_Preview">f'(\vx;\vd) = \lim_{\alpha\to 0^+} \frac{f(\vx+\alpha \vd) - f(\vx)}{\alpha} = \nabla f(\vx)\trans \vd</div>
<script type="math/tex; mode=display">f'(\vx;\vd) = \lim_{\alpha\to 0^+} \frac{f(\vx+\alpha \vd) - f(\vx)}{\alpha} = \nabla f(\vx)\trans \vd</script>
</div>
<p>We say a <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> function is flat at <span><span class="MathJax_Preview">\vx^*</span><script type="math/tex">\vx^*</script></span> if <span><span class="MathJax_Preview">f'(\vx) = 0</span><script type="math/tex">f'(\vx) = 0</script></span>. In terms of directional derivative, <span><span class="MathJax_Preview">f'(\vx) = 0</span><script type="math/tex">f'(\vx) = 0</script></span> is equivalent to the directional derivative of <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> equaling 
zero for all directions <span><span class="MathJax_Preview">\vd\in \R^n</span><script type="math/tex">\vd\in \R^n</script></span>, i.e.</p>
<div>
<div class="MathJax_Preview">\forall \vd\in \R^n,\; f'(\vx;\vd) = 0 \iff \nabla f(\vx) = 0</div>
<script type="math/tex; mode=display">\forall \vd\in \R^n,\; f'(\vx;\vd) = 0 \iff \nabla f(\vx) = 0</script>
</div>
<p>Similarly, for a twice-differentiable function <span><span class="MathJax_Preview">f:\R^n\to \Re</span><script type="math/tex">f:\R^n\to \Re</script></span>, the  directional second derivative is</p>
<div>
<div class="MathJax_Preview">f''(\vx;\vd) = \lim_{\alpha\to 0^+} \frac{f'(\vx+\alpha \vd;\vd) - f'(\vx;\vd)}{\alpha} = \vd\trans\nabla^2 f(\vx)\vd.</div>
<script type="math/tex; mode=display">f''(\vx;\vd) = \lim_{\alpha\to 0^+} \frac{f'(\vx+\alpha \vd;\vd) - f'(\vx;\vd)}{\alpha} = \vd\trans\nabla^2 f(\vx)\vd.</script>
</div>
<p>The second directional deriviate <span><span class="MathJax_Preview">f''(\vx;\vd)</span><script type="math/tex">f''(\vx;\vd)</script></span> provides curvature information of <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> at a point <span><span class="MathJax_Preview">\vx</span><script type="math/tex">\vx</script></span> along the direction <span><span class="MathJax_Preview">\vd</span><script type="math/tex">\vd</script></span>. This can be used to characterize
convex functions. Recall that a function is convex if for all <span><span class="MathJax_Preview">\vx,\vy</span><script type="math/tex">\vx,\vy</script></span> in its domain, and all  <span><span class="MathJax_Preview">0\leq \theta \leq 1</span><script type="math/tex">0\leq \theta \leq 1</script></span>, we have</p>
<div>
<div class="MathJax_Preview">f(\theta \vx + (1-\theta) \vy) \leq \theta f(\vx) + (1-\theta) f(\vy).</div>
<script type="math/tex; mode=display">f(\theta \vx + (1-\theta) \vy) \leq \theta f(\vx) + (1-\theta) f(\vy).</script>
</div>
<p>Equivalently, a function is convex if its directional second derivative is positive for all directions <span><span class="MathJax_Preview">d\in \R^n</span><script type="math/tex">d\in \R^n</script></span>, i.e.</p>
<div>
<div class="MathJax_Preview">\forall\ \vx \in \text{dom}(f),\; \forall \vd\in \R^n,\quad f''(\vx;\vd)\geq  0 </div>
<script type="math/tex; mode=display">\forall\ \vx \in \text{dom}(f),\; \forall \vd\in \R^n,\quad f''(\vx;\vd)\geq  0 </script>
</div>
<h2 id="sufficient-conditions-of-optimality"><strong>Sufficient conditions of optimality</strong><a class="headerlink" href="#sufficient-conditions-of-optimality" title="Permanent link">&para;</a></h2>
<p>We will state optimality conditions for the following minimization program</p>
<div>
<div class="MathJax_Preview">
\mathop{\text{minimize}}_{\vx\in \set{S}} \quad f(\vx),
</div>
<script type="math/tex; mode=display">
\mathop{\text{minimize}}_{\vx\in \set{S}} \quad f(\vx),
</script>
</div>
<p>where <span><span class="MathJax_Preview">f : \R^n\to\R</span><script type="math/tex">f : \R^n\to\R</script></span> is a real valued function. We say a point <span><span class="MathJax_Preview">\vx^*\in \set{S}</span><script type="math/tex">\vx^*\in \set{S}</script></span> is </p>
<ol>
<li>
<p>a minimizer of <span><span class="MathJax_Preview">f(\vx)</span><script type="math/tex">f(\vx)</script></span> if  <span><span class="MathJax_Preview">\nabla f(\vx^*) = 0</span><script type="math/tex">\nabla f(\vx^*) = 0</script></span> and <span><span class="MathJax_Preview">\vd^T\nabla^2 f(\vx^*) \vd &gt; 0</span><script type="math/tex">\vd^T\nabla^2 f(\vx^*) \vd > 0</script></span> for all <span><span class="MathJax_Preview">\vd\in \R^n</span><script type="math/tex">\vd\in \R^n</script></span>. 
Note that a square symmetrix matrix <span><span class="MathJax_Preview">\mA \in \R^{n\times n}</span><script type="math/tex">\mA \in \R^{n\times n}</script></span>, like the Hessian matrix, is positive definite if 
<span><span class="MathJax_Preview">\vz\trans\mA\vz &gt;0</span><script type="math/tex">\vz\trans\mA\vz >0</script></span> for all <span><span class="MathJax_Preview">\vz \in \R^n</span><script type="math/tex">\vz \in \R^n</script></span> (denoted by <span><span class="MathJax_Preview">\mA \succ 0</span><script type="math/tex">\mA \succ 0</script></span>).</p>
</li>
<li>
<p>a maximizer of <span><span class="MathJax_Preview">f(\vx)</span><script type="math/tex">f(\vx)</script></span> if  <span><span class="MathJax_Preview">\nabla f(\vx^*) = 0</span><script type="math/tex">\nabla f(\vx^*) = 0</script></span> and <span><span class="MathJax_Preview">\vd^T\nabla^2 f(\vx^*) \vd &lt; 0</span><script type="math/tex">\vd^T\nabla^2 f(\vx^*) \vd < 0</script></span> for all <span><span class="MathJax_Preview">\vd\in \R^n</span><script type="math/tex">\vd\in \R^n</script></span>. In this case, <span><span class="MathJax_Preview">\nabla^2 f(\vx^*)</span><script type="math/tex">\nabla^2 f(\vx^*)</script></span> is<br />
called a negative definite matrix and is denoted by <span><span class="MathJax_Preview">\mA \prec 0</span><script type="math/tex">\mA \prec 0</script></span>.</p>
</li>
</ol>
<p>Lastly, if <span><span class="MathJax_Preview">\nabla f(\vx^*) = 0</span><script type="math/tex">\nabla f(\vx^*) = 0</script></span> and <span><span class="MathJax_Preview">\nabla^2 f(x^*)</span><script type="math/tex">\nabla^2 f(x^*)</script></span> is indefinite, i.e. neither positive nor negative definite, then <span><span class="MathJax_Preview">\vx^*</span><script type="math/tex">\vx^*</script></span> is a saddle point. When 
<span><span class="MathJax_Preview">\nabla^2 f(x^*)</span><script type="math/tex">\nabla^2 f(x^*)</script></span> is indefinite then there exits directions where the 1-d slices of the function <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> are convex and concave.</p>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../Non-linear_LS/" title="Non-linear least squares" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Non-linear least squares
              </span>
            </div>
          </a>
        
        
          <a href="../Gradient_Descent/" title="Gradient descent" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Gradient descent
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2020 Michael Friedlander and Babhru Joshi
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.808e90bb.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"../.."}})</script>
      
        <script src="../../javascripts/extra.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>